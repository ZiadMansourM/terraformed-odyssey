---
# Ref: https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml

# Since we are using eks. The control plane is abstracted away from us.
# We do NOT need to manage ETCD, scheduler, controller-manager, and API server.
# The following will disable alerts for etcd and kube-scheduler.
defaultRules:
  rules:
    etcd: false
    kubeScheduler: false

# Then disable servicemonitors for them
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeEtcd:
  enabled: false

# Add a custom labels to discover ServiceMonitors
prometheus:
  prometheusSpec:
    ## If true, a nil or {} value for prometheus.prometheusSpec.serviceMonitorSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the servicemonitors created
    ##
    serviceMonitorSelectorNilUsesHelmValues: false

    serviceMonitorSelector: {}
      # matchLabels:
        # Prometheus will watch servicemonitors objects
        # with the following label:
        # e.g. app.kubernetes.io/monitored-by: prometheus
        # prometheus: monitor
    serviceMonitorNamespaceSelector: {}
      # matchLabels:
        # By default, prometheus will ONLY detect servicemonitors
        # in its own namespace `monitoring`. Instruct prometheus
        # to select service monitors in all namespaces with the
        # following label:
        # e.g. app.kubernetes.io/part-of: prometheus
        # monitoring: prometheus
    
    # https://github.com/prometheus-community/helm-charts/blob/fb9c3fec5bed0df7e864970853045883929d80c8/charts/kube-prometheus-stack/values.yaml#L3524
    ruleSelector:
      matchExpressions:
       - key: prometheus
         operator: In
         values:
         - prometheus-rules


# Last thing update common labels.
# If you did NOT add it. Prometheus Operator
# will IGNORE default service monitors created
# by this helm chart. Consequently, the prometheus 
# targets section will be empty.
# commonLabels:
#   prometheus: monitor
#   monitoring: prometheus

# Optionally, you can update the grafana admin password
grafana:
  adminPassword: testing321
  additionalDataSources:
  - name: Loki
    type: loki
    url: http://loki-loki-distributed-query-frontend.monitoring:3100

# Ref: https://prometheus.io/docs/alerting/latest/configuration/#configuration-file
# Ref: https://prometheus.io/webtools/alerting/routing-tree-editor/
# alertmanager:
#   config:
#     global:
#       resolve_timeout: 5m
#       slack_api_url: "https://hooks.slack.com/services/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"
#     route:
#       group_by: ['namespace'] # ['job']
#       group_wait: 30s
#       group_interval: 5m
#       repeat_interval: 12h
#       receiver: 'slack'
#       routes:
#       - receiver: 'null'
#         match:
#           alertname: DeadMansSwitch
#       - receiver: 'slack'
#         match:
#         continue: true
#     receivers:
#     - name: 'null'
#     - name: 'slack'
#       slack_configs:
#       - channel: '#alert-manager'
#         send_resolved: true
#         title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Monitoring Event Notification'
#         text: >-
#           {{ range .Alerts }}
#             *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
#             *Description:* {{ .Annotations.description }}
#             *Graph:* <{{ .GeneratorURL }}|:chart_with_upwards_trend:> *Runbook:* <{{ .Annotations.runbook }}|:spiral_note_pad:>
#             *Details:*
#             {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
#             {{ end }}
#           {{ end }}
